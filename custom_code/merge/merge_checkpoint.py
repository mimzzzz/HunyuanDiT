import torch
import safetensors.torch
import os
from transformers import T5Tokenizer, T5EncoderModel

# ================= 1. é…ç½®è·¯å¾„ (è‡ªåŠ¨é€‚é…ä½ çš„ç¯å¢ƒ) =================
# ä½ çš„å¾®è°ƒæ¨¡å‹ (DiT)
input_diffusion = "./hunyuan_dit_v1.2_finetuned_e2.pt"

# å®˜æ–¹åº•æ¨¡è·¯å¾„æ ¹ç›®å½•
base_root = "/data/aigc/HunyuanDiT-main/ckpts/t2i"

# CLIP (BERT) è·¯å¾„
input_bert = os.path.join(base_root, "clip_text_encoder/pytorch_model.bin")

# VAE è·¯å¾„ (æ³¨æ„ï¼šé€šå¸¸æ˜¯ diffusion_pytorch_model.safetensors)
# å¦‚æœä½ çš„ VAE æ–‡ä»¶å¤¹é‡Œæ˜¯ .binï¼Œè¯·çœ‹ä»£ç ä¸‹æ–¹çš„è‡ªåŠ¨åˆ¤æ–­é€»è¾‘
input_vae_dir = os.path.join(base_root, "sdxl-vae-fp16-fix")
input_vae = os.path.join(input_vae_dir, "diffusion_pytorch_model.safetensors")

# T5 è·¯å¾„ (ç›´æ¥åŠ è½½æœ¬åœ°ï¼Œä¸ç”¨ä¸‹è½½)
input_mt5_dir = os.path.join(base_root, "mt5")

# è¾“å‡ºæ–‡ä»¶å
output = "HunyuanDiT_v1.2_Finetuned_Full.safetensors"

print(f"ğŸš€ å¼€å§‹åˆå¹¶æ¨¡å‹...")
print(f"   DiT: {input_diffusion}")
print(f"   CLIP: {input_bert}")
print(f"   VAE: {input_vae}")
print(f"   T5: {input_mt5_dir}")

# ================= 2. åŠ è½½å¹¶å¤„ç†ç»„ä»¶ =================
out_sd = {}

# --- A. å¤„ç† CLIP (BERT) ---
print("â³ [1/4] Loading CLIP (Bert)...")
bert_sd = torch.load(input_bert, map_location="cpu", weights_only=False)  # å…¼å®¹æ€§ä¿®æ”¹
for k in bert_sd:
    if not k.startswith("visual."):
        out_sd["text_encoders.hydit_clip.transformer.{}".format(k)] = bert_sd[k].half()
del bert_sd

# --- B. å¤„ç† T5 (mT5) ---
print("â³ [2/4] Loading T5 (mT5-XL)... è¿™æ˜¯ä¸ªå¤§å—å¤´ï¼Œè¯·è€å¿ƒç­‰å¾…")
try:
    # ä¼˜å…ˆåŠ è½½æœ¬åœ°
    mt5 = T5EncoderModel.from_pretrained(input_mt5_dir, local_files_only=True)
    tokenizer = T5Tokenizer.from_pretrained(input_mt5_dir, local_files_only=True)
except Exception as e:
    print(f"âš ï¸ æœ¬åœ°åŠ è½½ T5 å¤±è´¥: {e}")
    print("å°è¯•ä» HuggingFace åœ¨çº¿åŠ è½½ (google/mt5-xl)...")
    mt5 = T5EncoderModel.from_pretrained("google/mt5-xl")
    tokenizer = T5Tokenizer.from_pretrained("google/mt5-xl")

# å¤„ç† T5 æƒé‡
t5_sd = mt5.state_dict()
for k in t5_sd:
    out_sd["text_encoders.mt5xl.transformer.{}".format(k)] = t5_sd[k].half()

# å¤„ç† Tokenizer (spiece.model) å¹¶åµŒå…¥æ–‡ä»¶
if hasattr(tokenizer, "sp_model"):
    print("   Embedding T5 spiece.model...")
    sp_model = torch.ByteTensor(list(tokenizer.sp_model.serialized_model_proto()))
    out_sd["text_encoders.mt5xl.spiece_model"] = sp_model
del mt5, t5_sd

# --- C. å¤„ç† DiT (ä½ çš„å¾®è°ƒæ¨¡å‹) ---
print("â³ [3/4] Loading DiT (Finetuned)...")
hydit = torch.load(input_diffusion, map_location="cpu", weights_only=False)
# è‡ªåŠ¨åˆ¤æ–­ Key æ ¼å¼
first_key = next(iter(hydit))
prefix = ""
if first_key.startswith("module."):
    prefix = "module."
    print("   Detected DeepSpeed prefix 'module.', removing it.")

for k, v in hydit.items():
    # æ¸…ç† DeepSpeed å‰ç¼€
    if prefix and k.startswith(prefix):
        clean_k = k[len(prefix):]
    else:
        clean_k = k

    # è¿™é‡Œçš„ key æ˜ å°„éå¸¸å…³é”®
    out_sd["model.{}".format(clean_k)] = v.half()
del hydit

# --- D. å¤„ç† VAE ---
print("â³ [4/4] Loading VAE...")
if not os.path.exists(input_vae):
    # å°è¯•æ‰¾ .bin
    input_vae_bin = os.path.join(input_vae_dir, "diffusion_pytorch_model.bin")
    if os.path.exists(input_vae_bin):
        print(f"   Found .bin VAE: {input_vae_bin}")
        vae_sd = torch.load(input_vae_bin, map_location="cpu")
    else:
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° VAE æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„: {input_vae_dir}")
else:
    vae_sd = safetensors.torch.load_file(input_vae)

for k in vae_sd:
    out_sd["vae.{}".format(k)] = vae_sd[k].half()
del vae_sd

# ================= 3. ä¿å­˜ =================
print(f"ğŸ’¾ Saving to {output} ...")
safetensors.torch.save_file(out_sd, output)
print("âœ… åˆå¹¶æˆåŠŸï¼è¿™å°±æ˜¯ä½ è¦çš„å®Œæ•´å•æ–‡ä»¶ Checkpointã€‚")
print("ğŸ‘‰ è¯·åœ¨ ComfyUI ä¸­ä½¿ç”¨ 'Load Checkpoint' èŠ‚ç‚¹ç›´æ¥åŠ è½½å®ƒã€‚")